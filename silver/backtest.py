import pandas as pd
import numpy as np
import os
from sklearn.ensemble import HistGradientBoostingClassifier, RandomForestClassifier, VotingClassifier
from sklearn.svm import SVC
from sklearn.preprocessing import StandardScaler
from sklearn.pipeline import make_pipeline
from sklearn.metrics import accuracy_score
from sklearn.feature_selection import RFE
from utils import load_silver_data, generate_silver_features, get_train_test_split

def silver_walk_forward_test(window_size=150, step=15):
    """
    Backtest 'Cuá»‘n chiáº¿u' cho Báº¡c (V7).
    """
    print(f"ğŸ•µï¸â€â™‚ï¸ Äang thá»±c hiá»‡n Backtest V7 cho Báº¡c (Window: {window_size} ngÃ y, Step: {step} ngÃ y)...")
    df = load_silver_data()
    df = generate_silver_features(df)
    
    results = []
    # Báº¯t Ä‘áº§u tá»« ngÃ y thá»© window_size, dá»± bÃ¡o tá»«ng Ä‘á»£t step ngÃ y
    for i in range(window_size, len(df) - step, step):
        train_df = df.iloc[:i]
        test_df = df.iloc[i:i+step]
        
        # Láº¥y features dá»±a trÃªn V7 logic
        X_train, y_train, _, _, feature_names = get_train_test_split(train_df, test_size=0.01)
        X_test = test_df[feature_names]
        y_test = test_df['target_dir']
        
        # Kiá»ƒm tra xem cÃ³ Ä‘á»§ 2 class Ä‘á»ƒ train khÃ´ng
        if len(np.unique(y_train)) < 2:
            print(f"âš ï¸ Giai Ä‘oáº¡n {test_df['date'].iloc[0].date()}: Bá» qua do dá»¯ liá»‡u há»c chá»‰ cÃ³ 1 nhÃ£n.")
            continue
            
        # V7: ThÃªm RFE Feature Selection trong má»—i loop backtest Ä‘á»ƒ loáº¡i bá» nhiá»…u
        base_rf = RandomForestClassifier(n_estimators=100, random_state=42)
        selector = RFE(base_rf, n_features_to_select=10, step=1)
        X_train_selected = selector.fit_transform(X_train, y_train)
        X_test_selected = selector.transform(X_test)
        
        # Train model V7 (Voting)
        base_models = [
            ('rf', RandomForestClassifier(n_estimators=300, max_depth=3, class_weight='balanced', random_state=42)),
            ('hgb', HistGradientBoostingClassifier(max_iter=50, max_depth=2, l2_regularization=50.0, random_state=42)),
            ('svc', make_pipeline(StandardScaler(), SVC(probability=True, kernel='linear', C=0.01, class_weight='balanced', random_state=42)))
        ]
        model = VotingClassifier(estimators=base_models, voting='soft', weights=[1, 1, 2])
        
        model.fit(X_train_selected, y_train)
        preds = model.predict(X_test_selected)
        acc = accuracy_score(y_test, preds)
        
        results.append(acc)
        print(f"ğŸ“… Giai Ä‘oáº¡n {test_df['date'].iloc[0].date()} -> {test_df['date'].iloc[-1].date()}: Acc = {acc*100:.2f}%")

    avg_acc = np.mean(results)
    print("\n" + "="*50)
    print(f"ğŸ“Š Äá»˜ CHÃNH XÃC TRUNG BÃŒNH (V7 BACKTEST): {avg_acc*100:.2f}%")
    print("="*50)
    
    if avg_acc > 0.55:
        print("ğŸš€ Há»‡ thá»‘ng V7 cho tháº¥y sá»± cáº£i thiá»‡n rÃµ rá»‡t!")
    elif avg_acc > 0.52:
        print("ğŸ“ˆ Há»‡ thá»‘ng báº¯t Ä‘áº§u á»•n Ä‘á»‹nh.")
    else:
        print("âš ï¸ Cáº§n tinh chá»‰nh thÃªm cÃ¡c Ä‘áº·c trÆ°ng vÄ© mÃ´.")

if __name__ == "__main__":
    silver_walk_forward_test()

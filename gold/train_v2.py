import os
import joblib
import pandas as pd
import numpy as np
from sklearn.ensemble import HistGradientBoostingClassifier, RandomForestClassifier, StackingClassifier
from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.preprocessing import StandardScaler
from sklearn.pipeline import make_pipeline
from sklearn.metrics import accuracy_score, classification_report
from utils_v2 import load_data, generate_advanced_features, get_train_test_split

from sklearn.feature_selection import RFE
from sklearn.ensemble import HistGradientBoostingClassifier, RandomForestClassifier, VotingClassifier

def train_and_evaluate():
    print("ğŸš€ Báº¯t Ä‘áº§u huáº¥n luyá»‡n mÃ´ hÃ¬nh V8 (Feature Selection & Voting)...")
    
    # 1. Load and Prepare Data
    df = load_data()
    df = generate_advanced_features(df)
    
    if df.empty:
        print("âŒ Dá»¯ liá»‡u trá»‘ng sau khi táº¡o Ä‘áº·c trÆ°ng.")
        return

    # 2. Split Data
    X_train, y_train, X_test, y_test, feature_names = get_train_test_split(df)
    
    print(f"ğŸ“Š Sá»‘ lÆ°á»£ng máº«u training: {len(X_train)}")
    print(f"ğŸ“Š Sá»‘ lÆ°á»£ng máº«u testing: {len(X_test)}")

    # 3. FEATURE SELECTION: Lá»c ra 12 Ä‘áº·c trÆ°ng tá»‘t nháº¥t Ä‘á»ƒ trÃ¡nh nhiá»…u
    # Vá»›i 300 máº«u, 12 Ä‘áº·c trÆ°ng lÃ  con sá»‘ "vÃ ng" Ä‘á»ƒ trÃ¡nh Overfitting
    selector = RFE(RandomForestClassifier(n_estimators=100, random_state=42), n_features_to_select=12)
    selector = selector.fit(X_train, y_train)
    selected_features = [f for f, s in zip(feature_names, selector.support_) if s]
    
    X_train_sel = X_train[selected_features]
    X_test_sel = X_test[selected_features]
    
    print(f"ğŸ¯ ÄÃ£ chá»n lá»c 12/25 Ä‘áº·c trÆ°ng quan trá»ng nháº¥t.")
    print(f"ğŸ“Š CÃ¡c Ä‘áº·c trÆ°ng giá»¯ láº¡i: {selected_features}")

    # 4. Äá»‹nh nghÄ©a cÃ¡c mÃ´ hÃ¬nh cÆ¡ sá»Ÿ (Base Models) vá»›i tham sá»‘ lá»³ lá»£m
    base_models = [
        ('rf', RandomForestClassifier(n_estimators=300, max_depth=5, min_samples_leaf=15, random_state=42)),
        ('hgb', HistGradientBoostingClassifier(max_iter=200, max_depth=3, l2_regularization=30.0, random_state=42)),
        ('svc', make_pipeline(StandardScaler(), SVC(probability=True, kernel='linear', C=0.1, random_state=42)))
    ]

    # 5. Sá»­ dá»¥ng Voting Classifier thay vÃ¬ Stacking Ä‘á»ƒ giáº£m Ä‘á»™ phá»©c táº¡p
    model = VotingClassifier(
        estimators=base_models,
        voting='soft', 
        weights=[1, 1, 0.8]
    )
    
    model.fit(X_train_sel, y_train)

    # 6. Evaluation
    y_pred = model.predict(X_test_sel)
    acc = accuracy_score(y_test, y_pred)
    
    print("\n" + "="*50)
    print(f"ğŸ† Äá»˜ CHÃNH XÃC V8 (Voting + RFE): {acc*100:.2f}%")
    print("="*50)
    print("\nBÃ¡o cÃ¡o chi tiáº¿t:")
    print(classification_report(y_test, y_pred))

    # 7. Save Model
    model_dir = os.path.join(os.path.dirname(__file__), "models")
    os.makedirs(model_dir, exist_ok=True)
    model_path = os.path.join(model_dir, "gold_v2_classifier.joblib")
    
    joblib.dump({
        'model': model,
        'feature_names': selected_features, # QUAN TRá»ŒNG: LÆ°u feature Ä‘Ã£ lá»c
        'accuracy': acc,
        'date': pd.Timestamp.now().strftime('%Y-%m-%d')
    }, model_path)
    
    print(f"âœ… ÄÃ£ lÆ°u mÃ´ hÃ¬nh táº¡i: {model_path}")

    # 6. Simple Backtest on Test Set
    # Láº¥y láº¡i pháº§n dá»¯ liá»‡u test tá»« dataframe gá»‘c Ä‘á»ƒ cÃ³ Ä‘áº§y Ä‘á»§ cÃ¡c cá»™t (nhÆ° target_ret)
    df_trainable = df.iloc[30:-1]
    test_results = df_trainable.iloc[-len(y_test):].copy()
    test_results['pred_dir'] = y_pred
    
    # Giáº£ Ä‘á»‹nh: Náº¿u Ä‘oÃ¡n Ä‘Ãºng 1 hoáº·c -1 thÃ¬ cÃ³ lá»i, náº¿u sai thÃ¬ lá»—
    # ÄÃ¢y lÃ  cÃ¡ch tÃ­nh lá»£i nhuáº­n Ä‘Æ¡n giáº£n dá»±a trÃªn hÆ°á»›ng Ä‘i
    test_results['profit'] = test_results.apply(
        lambda row: abs(row['target_ret']) if row['pred_dir'] == row['target_dir'] and row['pred_dir'] != 0
        else (-abs(row['target_ret']) if row['pred_dir'] != row['target_dir'] and row['pred_dir'] != 0 else 0),
        axis=1
    )
    
    cumulative_profit = (1 + test_results['profit']).prod() - 1
    print(f"ğŸ“ˆ Lá»£i nhuáº­n tÃ­ch lÅ©y giáº£ Ä‘á»‹nh trÃªn táº­p Test: {cumulative_profit*100:.2f}%")

if __name__ == "__main__":
    train_and_evaluate()

